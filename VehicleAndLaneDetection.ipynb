{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankitgrover/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/ankitgrover/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimage.feature import hog\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import deque\n",
    "## Import everything from helpers\n",
    "from helpers.utils import Utils\n",
    "from helpers.filterFalsePositive import FilterFalsePositive\n",
    "from helpers.classify import ClassifierUtil\n",
    "from helpers.vehicleDetector import VehicleDetector\n",
    "from helpers.calibration import Camera\n",
    "from helpers.warp import PerspectiveTransform\n",
    "from helpers.threshold import ThresholdUtil\n",
    "from helpers.line import Line\n",
    "from helpers.lane import LaneSearch\n",
    "% matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Load classifiers from pkl files\n",
    "from sklearn.externals import joblib\n",
    "svc = joblib.load('svcClassifier.pkl')\n",
    "X_scaler = joblib.load('xScaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Actual Parameters are used to identify cars from the images.\n",
    "y_start = 400\n",
    "y_stop = 656\n",
    "scale = 1.8\n",
    "orient = 12\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 4\n",
    "spatial_size = (32, 32)\n",
    "hist_bins = 128\n",
    "## Queue to store previous heatmaps and then club them together in last image frame\n",
    "## It helps in keeping car always under the heat blogs and removing false positives.\n",
    "heat_images = deque(maxlen = 3)\n",
    "utils = Utils()\n",
    "vehicle_detector = VehicleDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Detect vehicles using VehicleDetector class and find_cars funtion. \n",
    "## It is using HOG Subsampling approach internally to find cars.\n",
    "def find_cars(image):\n",
    "    return vehicle_detector.find_cars(image, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, window = 64)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Filter False positives using Heatmap and threshold.\n",
    "def filter_false_positives(image, bboxes_list):\n",
    "    filter_false_positive = FilterFalsePositive()\n",
    "    heat = filter_false_positive.convert_img_to_heat(image)\n",
    "    #print (bboxes)\n",
    "    heatmap = filter_false_positive.add_heat(bboxes_list)\n",
    "    ## Averaging last 3 heatmaps to smoothen the image frames output. \n",
    "    heat_images.append(heatmap)\n",
    "    heatmap = np.sum(np.array(heat_images), axis = 0)\n",
    "    heatmap = filter_false_positive.threshold(threshold = 5)\n",
    "    return heatmap, filter_false_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Draw labels on the image frame after removing false positives.\n",
    "## After thresholding only blobs of heat left around the cars positions.\n",
    "def labels(image, filter_false_positive):\n",
    "    filter_false_positive.labels()\n",
    "    labeled_img = filter_false_positive.draw_labeled_bboxes(image)\n",
    "    return labeled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Lane Detection\n",
    "\n",
    "## Camera Calibration\n",
    "## Load camera calibration images\n",
    "def load_camera_calibration_images(folder='camera_cal'):\n",
    "    camera_files = os.listdir(folder)\n",
    "    paths = list(map(lambda f: os.path.join(folder,f), camera_files))\n",
    "    print (paths)\n",
    "    cal_images = [mpimg.imread(path) for path in paths]\n",
    "    return cal_images\n",
    "\n",
    "## Load images from directory\n",
    "def load_img_from_dir(folder, filename):\n",
    "    path = os.path.join(folder, filename)\n",
    "    return mpimg.imread(path)\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['camera_cal/calibration1.jpg', 'camera_cal/calibration10.jpg', 'camera_cal/calibration11.jpg', 'camera_cal/calibration12.jpg', 'camera_cal/calibration13.jpg', 'camera_cal/calibration14.jpg', 'camera_cal/calibration15.jpg', 'camera_cal/calibration16.jpg', 'camera_cal/calibration17.jpg', 'camera_cal/calibration18.jpg', 'camera_cal/calibration19.jpg', 'camera_cal/calibration2.jpg', 'camera_cal/calibration20.jpg', 'camera_cal/calibration3.jpg', 'camera_cal/calibration4.jpg', 'camera_cal/calibration5.jpg', 'camera_cal/calibration6.jpg', 'camera_cal/calibration7.jpg', 'camera_cal/calibration8.jpg', 'camera_cal/calibration9.jpg']\n"
     ]
    }
   ],
   "source": [
    "## Load camera images and calibrate camera using Camera class\n",
    "images = load_camera_calibration_images()\n",
    "camera = Camera()\n",
    "mtx, dist = camera.calibrate(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define parmams that needs to be initialized before computing lanes in any input video.\n",
    "threshold_util = None\n",
    "lane_search = None\n",
    "perspective_transform = None\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    ## Initialize the objects before running images on the pipeline.\n",
    "    global index\n",
    "    global threshold_util \n",
    "    global lane_search\n",
    "    global perspective_transform\n",
    "    threshold_util = ThresholdUtil()\n",
    "    lane_search = LaneSearch()\n",
    "    perspective_transform = PerspectiveTransform()\n",
    "    index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Process the input image with the pipeline (Undistort Image -> \n",
    "Apply Combined Threshold technques: HLS (Only Saturation), Sobelx, Sobely, Magnitude and Directional Gradient -> \n",
    "Warp Image -> \n",
    "Histogram to identify the peaks ->\n",
    "Sliding Window or Look Ahead Filter to mask the peaks with polynomial fits ->\n",
    "Average the polynomial fit coefficients to smoothen the fits ->\n",
    "\n",
    "Sanity Check with Radius of Curvature)\n",
    "Pipeline for Vehicle Detection also (Find Cars -> Heatmap-> Thresholding Heatmap -> Labels the Cars)\n",
    "'''\n",
    "def process_image(image):\n",
    "    ## Lane Detection Pipeline.\n",
    "    global index\n",
    "    ## Undistort image.\n",
    "    undistort_img = camera.undistort(image)\n",
    "    index +=1\n",
    "    ## Create combined HLS (Saturation) color, sobel, magnitude and directional threshold image.\n",
    "    threshold_image = threshold_util.create_combined_color_thresh(undistort_img)\n",
    "    ## Warp the image using Perspective transform bird view.\n",
    "    warp_img = perspective_transform.warp(threshold_image)\n",
    "    ##cv2.imwrite(\"output_images/Warp\" + str(index) + \".jpg\",warp_img)\n",
    "    ## Search for a lane with confident coefficients or do searching first time\n",
    "    if (lane_search.confident):\n",
    "        ## Search for a lane with look ahead filter\n",
    "        draw_image = lane_search.sliding_window_look_ahead_filter(warp_img)\n",
    "    else:\n",
    "        ## Search for a lane and draw the results on the image   \n",
    "        draw_image = lane_search.sliding_window(warp_img)\n",
    "    undist_img_with_results = lane_search.draw_lane_results(warp_img, perspective_transform.Minv, undistort_img)\n",
    "    ### Vehicle Detection Pipeline\n",
    "    draw_img, bboxes = find_cars(undist_img_with_results)\n",
    "    heatmap, filter_false_positive = filter_false_positives(undist_img_with_results, bboxes)\n",
    "    undist_img_with_results = labels(undist_img_with_results, filter_false_positive)\n",
    "    return undist_img_with_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_video/project_video_lane_vehicle.mp4\n",
      "[MoviePy] Writing video output_video/project_video_lane_vehicle.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [12:52<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_video/project_video_lane_vehicle.mp4 \n",
      "\n",
      "CPU times: user 12min 5s, sys: 1min 53s, total: 13min 59s\n",
      "Wall time: 12min 53s\n"
     ]
    }
   ],
   "source": [
    "## Read Project video and ouput video with labels of Cars.\n",
    "from moviepy.editor import VideoFileClip\n",
    "init_params()\n",
    "output_video_path = 'output_video/project_video_lane_vehicle.mp4'\n",
    "input_clip = VideoFileClip(\"project_video.mp4\")\n",
    "output_clip = input_clip.fl_image(process_image)\n",
    "%time output_clip.write_videofile(output_video_path, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
